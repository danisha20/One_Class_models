{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of OCC DNN.ipynb","provenance":[{"file_id":"1VspFcV4ZXuoaLtskgcp9aR5nO4bFGfGj","timestamp":1602800879212}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"AdA-1G9Tcgn5"},"source":["import numpy as np \n","import pandas as pd\n","import tensorflow as tf\n","import os\n","import sys\n","import math\n","import csv\n","\n","from keras.callbacks import ModelCheckpoint\n","from sklearn.model_selection import train_test_split \n","from sklearn.svm import OneClassSVM\n","from sklearn.ensemble import IsolationForest\n","from sklearn.linear_model import Ridge\n","# the new model\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Flatten\n","\n","\n","from sklearn import metrics\n","from sklearn.metrics import classification_report \n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKj36C4lcwS8"},"source":["# Function importing Dataset \n","def importdata(trainFile, testFile): \n","    train = pd.read_csv(trainFile, sep= ',', header = None) \n","    test = pd.read_csv(testFile, sep= ',', header = None) \n","    return train, test    \n","\n","# Function to split target from data \n","def splitdataset(train, test): \n","    ohe = OneHotEncoder(sparse=True)\n","    objInTrain = len(train)\n","\n","    allData = pd.concat([train, test], ignore_index=True, sort =False, axis=0)\n","    AllDataWihoutClass = allData.iloc[:, :-1]\n","    AllDataWihoutClassOnlyNominals = AllDataWihoutClass.select_dtypes(include=['object'])\n","    AllDataWihoutClassNoNominals = AllDataWihoutClass.select_dtypes(exclude=['object'])\n","\n","    encAllDataWihoutClassNominals = ohe.fit_transform(AllDataWihoutClassOnlyNominals)\n","    encAllDataWihoutClassNominalsToPanda = pd.DataFrame(encAllDataWihoutClassNominals.toarray())\n","    \n","    if AllDataWihoutClassOnlyNominals.shape[1] > 0:\n","      codAllDataAgain = pd.concat([encAllDataWihoutClassNominalsToPanda, AllDataWihoutClassNoNominals], ignore_index=True, sort =False, axis=1)\n","    else:\n","      codAllDataAgain = AllDataWihoutClass\n","\n","    # Seperating the target variable \n","    X_train = codAllDataAgain[:objInTrain]\n","    y_train = train.values[:, -1]\n","\n","    X_test = codAllDataAgain[objInTrain:]\n","    y_test = test.values[:, -1]\n","    \n","    mm_scaler = MinMaxScaler()\n","    X_train_minmax = pd.DataFrame(mm_scaler.fit_transform(X_train[X_train.columns]), index=X_train.index, columns=X_train.columns)\n","    X_test_minmax = pd.DataFrame(mm_scaler.transform(X_test[X_test.columns]), index=X_test.index, columns=X_test.columns)\n","    \n","    std_scaler = StandardScaler()\n","    X_train_std = pd.DataFrame(std_scaler.fit_transform(X_train[X_train.columns]), index=X_train.index, columns=X_train.columns)\n","    X_test_std = pd.DataFrame(std_scaler.transform(X_test[X_test.columns]), index=X_test.index, columns=X_test.columns)\n","    \n","    X_train_minmax_std = pd.DataFrame(std_scaler.fit_transform(X_train_minmax[X_train_minmax.columns]), index=X_train_minmax.index, columns=X_train_minmax.columns)\n","    X_test_minmax_std = pd.DataFrame(std_scaler.transform(X_test_minmax[X_test_minmax.columns]), index=X_test_minmax.index, columns=X_test_minmax.columns)\n","    \n","    return X_train, X_test, y_train, y_test, X_train_minmax, X_test_minmax, X_train_std, X_test_std, X_train_minmax_std, X_test_minmax_std\n","\n","# Function to make predictions \n","def prediction(X_test, clf_object):  \n","    y_pred = clf_object.score_samples(X_test) \n","    return y_pred \n","\n","def result_of_Class(y_test, y_pred, saveFile):       \n","    np.savetxt(saveFile, y_pred, fmt='%.4f')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c7zDcxcPc3J3"},"source":["rootDir = '/content/drive/My Drive/Colab Notebooks/OCC_FromTavo'\n","\n","# Uncommment for using DNN\n","clf_classif = DNN2()\n","data = {'folder_name': [],\n","                'auc': []}\n","for dirName, subdirList, fileList in os.walk(rootDir):\n","    print('Directorio encontrado: %s' % dirName)\n","    print(\"************************************ DIRECTORIO **************************************\")\n","    if len(fileList) > 0: \n","        arr_auc = []\n","        arr_folder_name = dirName.split(\"/\")\n","        folder_name = arr_folder_name[len(arr_folder_name) - 1]\n","        completed_name = folder_name + \"-5-\"\n","        for i in range(1, int(len(fileList) / 2) + 1):\n","            print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! DATASET !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\") \n","            trainFile = str(dirName) + '/' + completed_name + str(i) +\"tra.dat.csv\"\n","            testFile = str(dirName) + '/' + completed_name + str(i) +\"tst.dat.csv\"\n","            print('trainFile ' + trainFile)\n","            print('testFile ' + testFile)\n","            # Loading data \n","            train, test = importdata(trainFile, testFile)\n","\n","            # Training\n","            X_train, X_test, y_train, y_test, X_train_minmax, X_test_minmax, X_train_std, X_test_std, X_train_minmax_std, X_test_minmax_std = splitdataset(train, test)\n","\n","            # Performing training \n","            clf_classif.fit(X_train, y_train) \n","\n","            # Operational Phase \n","            y_pred_classif = prediction(X_test, clf_classif) \n","\n","            auc = metrics.roc_auc_score(y_test,  y_pred_classif)\n","            arr_auc.append(1 - auc if auc < 0.5 else auc)\n","            print(\"AUC: \"+str(1 - auc if auc < 0.5 else auc))\n","            print(y_pred_classif)\n","\n","        print('AUC!! ' + str(arr_auc))\n","        aver_auc = sum(arr_auc) / len(arr_auc)\n","        print('aver_auc!! ' + str(aver_auc))\n","        data['folder_name'].append(folder_name)\n","        data['auc'].append(aver_auc)\n","        print('data[auc] ' + str(data['auc']))\n","\n","    df = pd.DataFrame(data, columns = ['folder_name', 'auc'])    \n","    df.to_csv('occ_results.csv')"],"execution_count":null,"outputs":[]}]}